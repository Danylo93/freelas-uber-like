import express from 'express';
import cors from 'cors';
import { createClient } from 'redis';
import { prisma, ProviderProfile } from '@freelas/database';
import { logger } from '@freelas/shared-logger';
import { KafkaClient } from '@freelas/shared-kafka';
import { CONFIG } from '@freelas/shared-config';
import { KAFKA_TOPICS, RequestCreatedEvent, OfferSentEvent, JobAcceptedEvent } from '@freelas/shared-contracts';

const app = express();
app.use(cors());
app.use(express.json());

const redis = createClient({ url: `redis://${CONFIG.REDIS.HOST}:${CONFIG.REDIS.PORT}` });
redis.connect().catch(e => logger.error('Redis connect error', e));

const kafka = new KafkaClient('matching-service', CONFIG.KAFKA.BROKERS);
kafka.connectProducer().catch(err => logger.error('Failed to connect Kafka Producer', err));

app.get('/healthz', (req, res) => {
  res.json({ status: 'ok', service: 'matching-service' });
});

// Accept Offer
app.post('/offers/:requestId/accept', async (req, res) => {
  const { requestId } = req.params;
  const { providerId } = req.body; // Injected by gateway or payload

  // Check if already matched
  const isLocked = await redis.get(`match:${requestId}`);
  if (isLocked) {
    return res.status(409).json({ message: 'Request already accepted by another provider' });
  }

  // Lock
  await redis.set(`match:${requestId}`, providerId);

  // Get request details (should call Request Service or have local cache, or just pass IDs)
  // We assume valid request if offer exists.
  // We publish JOB_ACCEPTED.

  // We need customerId. Ideally we stored it in Redis when sending offers.
  const requestDataStr = await redis.get(`request:${requestId}`);
  if (!requestDataStr) {
     return res.status(400).json({ message: 'Request expired or not found' });
  }
  const requestData = JSON.parse(requestDataStr);

  const event: JobAcceptedEvent = {
    requestId,
    jobId: '', // Will be generated by Request Service or we generate here? Contracts say Request Service creates Job.
    // Actually Event says jobId. Let's generate UUID here or let Request Service do it.
    // If we generate here, we ensure ID consistency.
    // But Request Service creates the record.
    // Let's send requestId and providerId. The consumer will create the job.
    // The consumer in Request Service creates the job.
    providerId,
    customerId: requestData.customerId
  };

  await kafka.publish(KAFKA_TOPICS.JOB_ACCEPTED, event);

  res.json({ status: 'accepted' });
});

// Consumer for Request Created
async function setupConsumers() {
  const consumer = new KafkaClient('matching-service-consumer', CONFIG.KAFKA.BROKERS);
  await consumer.connectConsumer('matching-service-group', [KAFKA_TOPICS.REQUEST_CREATED], async (payload) => {
    const data = JSON.parse(payload.message.value?.toString() || '{}') as RequestCreatedEvent;
    logger.info('Matching Service received Request', data);

    // Save request data to Redis for later retrieval during accept
    await redis.set(`request:${data.requestId}`, JSON.stringify(data), { EX: 300 }); // 5 mins TTL

    // 1. Find Providers
    // Simple logic: Find all online providers.
    // Advanced: Filter by Category + Distance.

    // We'll use Prisma to find providers.
    // Note: In a real app, use PostGIS 'ST_DWithin'.
    // Here we fetch all online providers and filter by Haversine in memory (if list is small) or just fetch all for MVP.
    const providers = await prisma.providerProfile.findMany({
      where: {
        isOnline: true,
        // specialties: { has: data.categoryId } // Prisma array filter
      },
      include: { user: true }
    });

    logger.info(`Found ${providers.length} online providers`);

    // Filter by specialties (manual if Prisma doesn't support 'has' on string[] depending on DB capability, Postgres supports it)
    // And Distance.
    const MAX_DISTANCE_KM = 10;

    for (const provider of providers) {
      if (provider.specialties.includes(data.categoryId) || provider.specialties.length === 0) { // Assume empty = all for test
         // Check distance
         if (provider.currentLat && provider.currentLng) {
            const dist = getDistanceFromLatLonInKm(data.lat, data.lng, provider.currentLat, provider.currentLng);
            if (dist <= MAX_DISTANCE_KM) {
                // Send Offer
                const offer: OfferSentEvent = {
                    requestId: data.requestId,
                    providerId: provider.userId,
                    timeout: 30
                };
                await kafka.publish(KAFKA_TOPICS.MATCHING_OFFER_SENT, offer);
            }
         } else {
             // Provider location unknown, skip or send anyway? Skip.
         }
      }
    }
  });
}

function getDistanceFromLatLonInKm(lat1: number, lon1: number, lat2: number, lon2: number) {
  var R = 6371; // Radius of the earth in km
  var dLat = deg2rad(lat2-lat1);  // deg2rad below
  var dLon = deg2rad(lon2-lon1);
  var a =
    Math.sin(dLat/2) * Math.sin(dLat/2) +
    Math.cos(deg2rad(lat1)) * Math.cos(deg2rad(lat2)) *
    Math.sin(dLon/2) * Math.sin(dLon/2)
    ;
  var c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));
  var d = R * c; // Distance in km
  return d;
}

function deg2rad(deg: number) {
  return deg * (Math.PI/180)
}

setupConsumers().catch(e => logger.error(e));

const PORT = process.env.PORT || 3005;
app.listen(PORT, () => {
  logger.info(`matching-service listening on port ${PORT}`);
});
